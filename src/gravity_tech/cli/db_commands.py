"""
Database CLI Commands

Ø¯Ø³ØªÙˆØ±Ø§Øª CLI Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯ÛŒØªØ§Ø¨ÛŒØ³:
- Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ Ø¬Ø¯Ø§ÙˆÙ„
- Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
- Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ schema
- Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø¬Ø¯Ø§ÙˆÙ„
- Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª
- Ø¨Ú©Ø§Ù¾ Ùˆ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ

Author: Gravity Tech Team
Date: December 5, 2025
Version: 1.0.0
License: MIT
"""

from __future__ import annotations

import gzip
import json
import re
import sqlite3
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, cast

import click
from gravity_tech.config.settings import settings
from gravity_tech.database.database_manager import DatabaseManager, DatabaseType

try:
    from psycopg2 import Error as PsycopgError  # type: ignore
except Exception:  # pragma: no cover - optional dependency
    PsycopgError = ()  # type: ignore


DEFAULT_SQLITE_PATH = settings.sqlite_path
IDENTIFIER_RE = re.compile(r"^[A-Za-z0-9_]+$")


def _validate_identifier(value: str, label: str) -> str:
    if not value or not IDENTIFIER_RE.fullmatch(value):
        raise click.BadParameter(
            f"{label} Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· Ø´Ø§Ù…Ù„ Ø­Ø±ÙˆÙØŒ Ø§Ø¹Ø¯Ø§Ø¯ ÛŒØ§ '_' Ø¨Ø§Ø´Ø¯.",
            param_hint=label
        )
    return value


def _format_db_error(error: Exception) -> str:
    if isinstance(error, FileNotFoundError):
        return "ÙØ§ÛŒÙ„ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ù…Ø³ÛŒØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯."
    if isinstance(error, PermissionError):
        return "Ø¯Ø³ØªØ±Ø³ÛŒ Ù†ÙˆØ´ØªÙ†/Ø®ÙˆØ§Ù†Ø¯Ù† Ø¨Ù‡ ÙØ§ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."
    if isinstance(error, sqlite3.Error):
        return f"Ø®Ø·Ø§ÛŒ SQLite: {error}"
    if PsycopgError and isinstance(error, PsycopgError):
        return f"Ø®Ø·Ø§ÛŒ PostgreSQL: {error}"
    return str(error)


def _parse_filters(filters: tuple[str, ...]) -> list[tuple[str, str]]:
    parsed: list[tuple[str, str]] = []
    for raw_filter in filters:
        if "=" not in raw_filter:
            raise click.BadParameter(
                "ÙÛŒÙ„ØªØ± Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ø´Ú©Ù„ column=value Ø¨Ø§Ø´Ø¯.",
                param_hint="filter"
            )
        column, value = raw_filter.split("=", 1)
        column = column.strip()
        value = value.strip()
        _validate_identifier(column, "Ù†Ø§Ù… Ø³ØªÙˆÙ†")
        parsed.append((column, value))
    return parsed


def _build_filter_clause(
    parsed_filters: list[tuple[str, str]],
    db_manager: DatabaseManager
) -> tuple[str, tuple[Any, ...]]:
    if not parsed_filters:
        return "", ()

    placeholder = db_manager.get_sql_placeholder()
    clauses: list[str] = []
    params: list[Any] = []

    for column, value in parsed_filters:
        clauses.append(f"{column} = {placeholder}")
        params.append(value)

    return " AND ".join(clauses), tuple(params)


def _parse_query_params(
    params: tuple[str, ...],
    params_json: str | None
) -> tuple[Any, ...] | None:
    if params_json:
        try:
            parsed = json.loads(params_json)
        except json.JSONDecodeError as exc:
            raise click.BadParameter(
                f"JSON Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª: {exc}"
            ) from exc
        if not isinstance(parsed, list):
            raise click.BadParameter("Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¨Ø§ÛŒØ¯ Ù„ÛŒØ³Øª JSON Ø¨Ø§Ø´Ù†Ø¯.")
        return tuple(parsed)

    if params:
        return tuple(params)

    return None


def _open_backup_writer(path: Path, compress: bool):
    if compress:
        return gzip.open(path, 'wt', encoding='utf-8')
    return open(path, 'w', encoding='utf-8')


def _open_backup_reader(path: str):
    if path.lower().endswith('.gz'):
        return gzip.open(path, 'rt', encoding='utf-8')
    return open(path, encoding='utf-8')


def _record_matches_filters(record: dict[str, Any], filters: list[tuple[str, str]]) -> bool:
    for column, value in filters:
        if str(record.get(column)) != value:
            return False
    return True


def _stream_backup_to_file(
    db_manager: DatabaseManager,
    tables: list[str],
    output_file: Path,
    compress: bool,
    chunk_size: int
) -> dict[str, int]:
    metadata = {
        "timestamp": datetime.now().isoformat(),
        "database": db_manager.get_database_info()
    }
    table_counts: dict[str, int] = {}

    with _open_backup_writer(output_file, compress) as handle:
        handle.write('{\n')
        handle.write('  "metadata": ')
        metadata_json = json.dumps(metadata, ensure_ascii=False, indent=2)
        handle.write(metadata_json.replace('\n', '\n  '))
        handle.write(',\n')
        handle.write('  "data": {\n')

        for idx, table in enumerate(tables):
            handle.write(f'    "{table}": [\n')
            record_count = 0
            first_record = True
            for record in db_manager.stream_table_records(table, chunk_size=chunk_size):
                record_count += 1
                serialized = json.dumps(record, ensure_ascii=False, default=str)
                prefix = "" if first_record else ","
                handle.write(f'      {prefix}{serialized}\n')
                first_record = False
            handle.write('    ]')
            if idx < len(tables) - 1:
                handle.write(',\n')
            else:
                handle.write('\n')
            table_counts[table] = record_count

        handle.write('  }\n')
        handle.write('}\n')

    return table_counts


@click.group()
def db_cli():
    """Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…Ø¯ÛŒØ±ÛŒØª Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Gravity Tech"""
    pass


@db_cli.command()
@click.option('--type', 'db_type',
              type=click.Choice(['postgresql', 'sqlite', 'auto'], case_sensitive=False),
              default='auto',
              help='Ù†ÙˆØ¹ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (auto Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø±)')
@click.option('--connection', 'connection_string',
              default=None,
              help='Ø±Ø´ØªÙ‡ Ø§ØªØµØ§Ù„ PostgreSQL (Ù…Ø«Ø§Ù„: postgresql://user:pass@localhost/dbname)')
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
@click.option('--force', is_flag=True,
              help='Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÙˆØ¬ÙˆØ¯')
def init(db_type: str, connection_string: str | None, sqlite_path: str, force: bool):
    """
    Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ Ø¬Ø¯Ø§ÙˆÙ„

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands init
        python -m gravity_tech.cli.db_commands init --type postgresql --connection "postgresql://user:pass@localhost/gravity"
        python -m gravity_tech.cli.db_commands init --type sqlite --sqlite-path data/mydb.db
    """
    click.echo("ğŸš€ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")

    try:
        # Determine database type
        if db_type == 'auto':
            db_type_enum = None  # Let DatabaseManager auto-detect
            click.echo("ğŸ” ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ù†ÙˆØ¹ Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")
        elif db_type == 'postgresql':
            db_type_enum = DatabaseType.POSTGRESQL
            click.echo("ğŸ˜ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² PostgreSQL")
        else:
            db_type_enum = DatabaseType.SQLITE
            click.echo("ğŸ’¾ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SQLite")

        # Initialize database manager
        db_manager = DatabaseManager(
            db_type=db_type_enum,
            connection_string=connection_string,
            sqlite_path=sqlite_path,
            auto_setup=False  # We'll setup manually
        )

        # Check if database exists (use public method)
        db_info = db_manager.get_database_info()
        if not force and db_info.get('connected', False):
            if not click.confirm('âš ï¸ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù‚Ø¨Ù„Ø§Ù‹ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ú©Ù†ÛŒØ¯ØŸ'):
                click.echo("âŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.")
                return

        # Setup database
        click.echo("ğŸ“¦ Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„...")
        db_manager.setup_database()

        # Show database info
        info = db_manager.get_database_info()
        click.echo("\nâœ… Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯!")
        click.echo(f"   Ù†ÙˆØ¹: {info['type']}")
        click.echo(f"   Ù…Ø³ÛŒØ±: {info.get('path', info.get('connection', 'N/A'))}")
        click.echo(f"   ØªØ¹Ø¯Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„: {info.get('table_count', 0)}")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
def status(sqlite_path: str):
    """
    Ù†Ù…Ø§ÛŒØ´ ÙˆØ¶Ø¹ÛŒØª Ø¯ÛŒØªØ§Ø¨ÛŒØ³

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands status
    """
    click.echo("ğŸ” Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")

    try:

        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)
        info = db_manager.get_database_info()
        if not info.get('connected', False):
            click.echo("âŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ Ø¯Ø³ØªÙˆØ± 'init' Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø±Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯.")
            sys.exit(1)

        stats = cast(dict[str, int], db_manager.get_statistics())

        click.echo("\nğŸ“Š Database Status:")
        click.echo(f"   Type: {info['type']}")
        click.echo(f"   Status: {'âœ… Active' if info.get('connected', False) else 'âŒ Inactive'}")
        click.echo(f"   Path: {info.get('path', info.get('connection', 'N/A'))}")
        click.echo(f"   Table count: {info.get('table_count', 0)}")

        if stats:
            click.echo("\nğŸ“ˆ Table Stats:")
            for table, count in stats.items():
                click.echo(f"   {table}: {count:,} records")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.argument('table_name')
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
@click.option('--force', is_flag=True,
              help='Ø¨Ø¯ÙˆÙ† ØªØ£ÛŒÛŒØ¯ Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ú©Ù†')
def reset_table(table_name: str, sqlite_path: str, force: bool):
    """
    Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ ÛŒÚ© Ø¬Ø¯ÙˆÙ„ (Ø­Ø°Ù ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§)

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands reset-table historical_scores
        python -m gravity_tech.cli.db_commands reset-table historical_scores --force
    """
    original_table_name = table_name
    click.echo(f"âš ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø¬Ø¯ÙˆÙ„ '{original_table_name}'...")

    try:
        table_name = _validate_identifier(table_name, "Ù†Ø§Ù… Ø¬Ø¯ÙˆÙ„")
    except click.BadParameter as err:
        click.echo(f"âŒ {err.message}", err=True)
        return

    if not force:
        if not click.confirm(f'Ø¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ "{table_name}" Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯?'):
            click.echo("âŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.")
            return

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)

        # Get count before
        stats_before = cast(dict[str, int], db_manager.get_statistics())
        count_before = stats_before.get(table_name, 0)

        # Reset table
        db_manager.reset_table(table_name)

        click.echo(f"âœ… Ø¬Ø¯ÙˆÙ„ '{table_name}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø´Ø¯.")
        click.echo(f"   ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: {count_before:,}")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø¬Ø¯ÙˆÙ„: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
@click.option('--force', is_flag=True,
              help='Ø¨Ø¯ÙˆÙ† ØªØ£ÛŒÛŒØ¯ Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ú©Ù†')
def reset_all(sqlite_path: str, force: bool):
    """
    Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ ØªÙ…Ø§Ù… Ø¬Ø¯Ø§ÙˆÙ„ (Ø­Ø°Ù ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§)

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands reset-all
        python -m gravity_tech.cli.db_commands reset-all --force
    """
    click.echo("âš ï¸âš ï¸âš ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ ØªÙ…Ø§Ù… Ø¬Ø¯Ø§ÙˆÙ„...")

    if not force:
        if not click.confirm('Ø¢ÛŒØ§ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ…Ø§Ù… Ø¬Ø¯Ø§ÙˆÙ„ Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯?'):
            click.echo("âŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.")
            return
        if not click.confirm('Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ù‚Ø§Ø¨Ù„ Ø¨Ø§Ø²Ú¯Ø´Øª Ù†ÛŒØ³Øª! Ø¢ÛŒØ§ Ú©Ø§Ù…Ù„Ø§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒØ¯?'):
            click.echo("âŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.")
            return

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)

        # Get stats before
        stats_before = cast(dict[str, int], db_manager.get_statistics())
        total_before = sum(stats_before.values())

        # Reset all tables
        for table_name in stats_before.keys():
            db_manager.reset_table(table_name)
            click.echo(f"   âœ“ {table_name}: {stats_before[table_name]:,} Ø±Ú©ÙˆØ±Ø¯ Ø­Ø°Ù Ø´Ø¯")

        click.echo("\nâœ… ØªÙ…Ø§Ù… Ø¬Ø¯Ø§ÙˆÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø´Ø¯Ù†Ø¯.")
        click.echo(f"   Ù…Ø¬Ù…ÙˆØ¹ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: {total_before:,}")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø¬Ø¯Ø§ÙˆÙ„: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
def migrate(sqlite_path: str):
    """
    Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ schema Ø¯ÛŒØªØ§Ø¨ÛŒØ³

    Ø§ÛŒÙ† Ø¯Ø³ØªÙˆØ± schema Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø±Ø§ Ø¨Ø§ Ø¢Ø®Ø±ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ù‡Ù…Ú¯Ø§Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands migrate
    """
    click.echo("ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ schema Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)

        # Run migrations
        click.echo("ğŸ“ Ø¨Ø±Ø±Ø³ÛŒ ØªØºÛŒÛŒØ±Ø§Øª...")
        migrations_applied = db_manager.run_migrations()

        if migrations_applied:
            click.echo(f"âœ… {len(migrations_applied)} migration Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯:")
            for migration in migrations_applied:
                click.echo(f"   âœ“ {migration}")
        else:
            click.echo("âœ… Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ù‡â€ŒØ±ÙˆØ² Ø§Ø³Øª. Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ migration Ù†ÛŒØ³Øª.")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± migration: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.option('--output', 'output_path',
              default=None,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: backup_YYYYMMDD_HHMMSS.json[.gz])')
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
@click.option('--tables', 'table_names',
              default=None,
              help='Ù„ÛŒØ³Øª Ø¬Ø¯Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ backup (Ø¨Ø§ Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ø´ÙˆÙ†Ø¯ØŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ù‡Ù…Ù‡)')
@click.option('--compress/--no-compress',
              default=True,
              help='Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø¨Ù‡ Ø´Ú©Ù„ gzip Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù…')
@click.option('--chunk-size', 'chunk_size',
              default=1000,
              type=int,
              show_default=True,
              help='ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± Ù‡Ø± Ù…Ø±Ø­Ù„Ù‡ (Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡)')
def backup(output_path: str | None, sqlite_path: str, table_names: str | None,
           compress: bool, chunk_size: int):
    """
    Ø§ÛŒØ¬Ø§Ø¯ backup Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands backup
        python -m gravity_tech.cli.db_commands backup --output backup.json
        python -m gravity_tech.cli.db_commands backup --tables historical_scores,tool_performance
    """
    click.echo("ğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ backup...")

    if chunk_size <= 0:
        raise click.BadParameter("chunk-size Ø¨Ø§ÛŒØ¯ Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ø§Ø² ØµÙØ± Ø¨Ø§Ø´Ø¯.", param_hint="chunk-size")

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)

        # Parse table names
        if table_names:
            tables = [
                _validate_identifier(name.strip(), "Ù†Ø§Ù… Ø¬Ø¯ÙˆÙ„")
                for name in table_names.split(',')
                if name.strip()
            ]
        else:
            tables = db_manager.get_tables()

        if not tables:
            click.echo("â„¹ï¸ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ÛŒ Ø¨Ø±Ø§ÛŒ backup Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
            return

        # Generate filename if not provided
        if not output_path:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            extension = ".json.gz" if compress else ".json"
            output_path = f"backup_{timestamp}{extension}"

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        table_counts = _stream_backup_to_file(
            db_manager=db_manager,
            tables=tables,
            output_file=output_file,
            compress=compress,
            chunk_size=chunk_size
        )

        total_records = sum(table_counts.values())
        file_size = output_file.stat().st_size / 1024  # KB

        click.echo("âœ… Backup Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯:")
        click.echo(f"   ÙØ§ÛŒÙ„: {output_file}")
        click.echo(f"   Ø­Ø¬Ù…: {file_size:.2f} KB")
        click.echo(f"   ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§: {total_records:,}")
        click.echo(f"   Ø¬Ø¯Ø§ÙˆÙ„: {', '.join(tables)}")
        click.echo(f"   ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ: {'ÙØ¹Ø§Ù„' if compress else 'ØºÛŒØ±ÙØ¹Ø§Ù„'}")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ backup: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.argument('backup_file', type=click.Path(exists=True))
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
@click.option('--force', is_flag=True,
              help='Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯')
def restore(backup_file: str, sqlite_path: str, force: bool):
    """
    Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø§Ø² backup

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands restore backup.json
        python -m gravity_tech.cli.db_commands restore backup_20251205_120000.json --force
    """
    click.echo(f"â™»ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø² backup: {backup_file}")

    if not force:
        if not click.confirm('âš ï¸ Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒØ¯?'):
            click.echo("âŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.")
            return

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)

        # Load backup file
        with _open_backup_reader(backup_file) as f:
            backup_data = json.load(f)

        # Restore
        click.echo("ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
        result = db_manager.restore_backup(backup_data)

        click.echo("âœ… Backup Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯:")
        for table, count in result.items():
            click.echo(f"   âœ“ {table}: {count:,} Ø±Ú©ÙˆØ±Ø¯")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ backup: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.argument('json_file', type=click.Path(exists=True))
@click.option('--table', 'table_name',
              required=True,
              help='Ù†Ø§Ù… Ø¬Ø¯ÙˆÙ„ Ø¨Ø±Ø§ÛŒ insert')
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
@click.option('--batch-size', 'batch_size',
              default=1000,
              help='ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ Ø¯Ø± Ù‡Ø± batch')
def import_data(json_file: str, table_name: str, sqlite_path: str, batch_size: int):
    """
    import Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„ JSON

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands import-data data.json --table historical_scores
    """
    click.echo(f"ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ import Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø²: {json_file}")

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)

        # Load data
        with open(json_file, encoding='utf-8') as f:
            data = json.load(f)

        # Import
        if isinstance(data, list):
            records = cast(list[dict[str, Any]], data)
        elif isinstance(data, dict) and table_name in data:
            records = cast(list[dict[str, Any]], data[table_name])
        else:
            raise ValueError("ÙØ±Ù…Øª ÙØ§ÛŒÙ„ JSON Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª")

        click.echo(f"ğŸ“Š {len(records):,} Ø±Ú©ÙˆØ±Ø¯ ÛŒØ§ÙØª Ø´Ø¯...")

        # Import in batches
        imported = 0
        with click.progressbar(length=len(records), label='Ø¯Ø± Ø­Ø§Ù„ import') as bar:
            for i in range(0, len(records), batch_size):
                batch = records[i:i+batch_size]
                db_manager.bulk_insert(table_name, batch)
                imported += len(batch)
                bar.update(len(batch))

        click.echo(f"âœ… {imported:,} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª import Ø´Ø¯Ù†Ø¯.")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± import Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.argument('table_name')
@click.option('--output', 'output_file',
              default=None,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: TABLE_NAME_export.json)')
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
@click.option('--limit', 'limit',
              default=None,
              type=int,
              help='Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§')
@click.option('--filter', 'filters',
              multiple=True,
              help='ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§ÛŒÙ…Ù† column=value (Ù‚Ø§Ø¨Ù„ ØªÚ©Ø±Ø§Ø±)')
def export_table(table_name: str, output_file: str | None, sqlite_path: str,
                 limit: int | None, filters: tuple[str, ...]):
    """
    export ÛŒÚ© Ø¬Ø¯ÙˆÙ„ Ø¨Ù‡ ÙØ§ÛŒÙ„ JSON

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands export-table historical_scores
        python -m gravity_tech.cli.db_commands export-table historical_scores --limit 100
        python -m gravity_tech.cli.db_commands export-table historical_scores --filter symbol=BTCUSDT --filter timeframe=1h
    """
    original_table_name = table_name
    click.echo(f"ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ export Ø¬Ø¯ÙˆÙ„ '{original_table_name}'...")
    parsed_filters = _parse_filters(filters)

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)
        if db_manager.db_type == DatabaseType.JSON_FILE:
            filter_clause = ""
            params: tuple[Any, ...] = ()
        else:
            filter_clause, params = _build_filter_clause(parsed_filters, db_manager)

        table_name = _validate_identifier(table_name, "Ù†Ø§Ù… Ø¬Ø¯ÙˆÙ„")

        query = f"SELECT * FROM {table_name}"
        if filter_clause:
            query += f" WHERE {filter_clause}"
        if limit:
            query += f" LIMIT {limit}"

        if db_manager.db_type == DatabaseType.JSON_FILE:
            records: list[dict[str, Any]] = []
            for record in db_manager.stream_table_records(table_name):
                if parsed_filters and not _record_matches_filters(record, parsed_filters):
                    continue
                records.append(record)
                if limit and len(records) >= limit:
                    break
        else:
            records = cast(
                list[dict[str, Any]],
                db_manager.execute_query(
                    query,
                    params=params if params else None,
                    fetch=True
                )
            ) or []

        # Generate filename if not provided
        if not output_file:
            output_file = f"{table_name}_export.json"

        # Save to file
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(records, f, ensure_ascii=False, indent=2, default=str)

        file_size = output_path.stat().st_size / 1024  # KB

        click.echo("âœ… Ø¬Ø¯ÙˆÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª export Ø´Ø¯:")
        click.echo(f"   ÙØ§ÛŒÙ„: {output_path}")
        click.echo(f"   Ø­Ø¬Ù…: {file_size:.2f} KB")
        click.echo(f"   ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§: {len(records):,}")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± export Ø¬Ø¯ÙˆÙ„: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.argument('query')
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
@click.option('--output', 'output_file',
              default=None,
              help='Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± ÙØ§ÛŒÙ„ JSON')
@click.option('--param', 'params',
              multiple=True,
              help='Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø¨Ø±Ø§ÛŒ placeholder (Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú†Ù†Ø¯ Ø¨Ø§Ø± ØªÚ©Ø±Ø§Ø± Ú©Ù†ÛŒØ¯)')
@click.option('--params-json', 'params_json',
              default=None,
              help='ØªØ¹Ø±ÛŒÙ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª JSON list (Ù…Ø«Ø§Ù„: "[\\"BTCUSDT\\", 10]")')
def query(query: str, sqlite_path: str, output_file: str | None,
          params: tuple[str, ...], params_json: str | None):
    """
    Ø§Ø¬Ø±Ø§ÛŒ ÛŒÚ© query Ø¯Ù„Ø®ÙˆØ§Ù‡

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands query "SELECT COUNT(*) FROM historical_scores"
        python -m gravity_tech.cli.db_commands query "SELECT * FROM historical_scores WHERE symbol = %s" --param BTCUSDT
    """
    click.echo("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ÛŒ query...")

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)
        if db_manager.db_type == DatabaseType.JSON_FILE:
            click.echo("âŒ Ø§Ø¬Ø±Ø§ÛŒ query Ø±ÙˆÛŒ Ø°Ø®ÛŒØ±Ù‡ JSON Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.", err=True)
            sys.exit(1)

        query_params = _parse_query_params(params, params_json)

        results = cast(
            list[dict[str, Any]],
            db_manager.execute_query(query, params=query_params, fetch=True)
        ) or []

        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            click.echo(f"âœ… Ù†ØªØ§ÛŒØ¬ Ø¯Ø± '{output_file}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")
        else:
            click.echo(f"\nğŸ“Š Ù†ØªØ§ÛŒØ¬ ({len(results)} Ø±Ú©ÙˆØ±Ø¯):")
            for i, row in enumerate(results[:10], 1):
                click.echo(f"\n   Ø±Ú©ÙˆØ±Ø¯ {i}:")
                for key, value in row.items():
                    click.echo(f"      {key}: {value}")

            if len(results) > 10:
                click.echo(f"\n   ... Ùˆ {len(results) - 10} Ø±Ú©ÙˆØ±Ø¯ Ø¯ÛŒÚ¯Ø±")

        click.echo(f"\nâœ… Query Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯. ({len(results)} Ø±Ú©ÙˆØ±Ø¯)")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ query: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
def tables(sqlite_path: str):
    """
    Ù†Ù…Ø§ÛŒØ´ Ù„ÛŒØ³Øª Ø¬Ø¯Ø§ÙˆÙ„

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands tables
    """
    click.echo("ğŸ“‹ Ø¬Ø¯Ø§ÙˆÙ„ Ù…ÙˆØ¬ÙˆØ¯:")

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)

        table_list = cast(list[str], db_manager.get_tables())
        stats = cast(dict[str, int], db_manager.get_statistics())

        if not table_list:
            click.echo("   Ù‡ÛŒÚ† Ø¬Ø¯ÙˆÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return

        click.echo(f"\n   ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„: {len(table_list)} Ø¬Ø¯ÙˆÙ„\n")

        for table in table_list:
            count = stats.get(table, 0)
            click.echo(f"   â€¢ {table}: {count:,} Ø±Ú©ÙˆØ±Ø¯")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¬Ø¯Ø§ÙˆÙ„: {_format_db_error(e)}", err=True)
        sys.exit(1)


@db_cli.command()
@click.argument('table_name')
@click.option('--sqlite-path', 'sqlite_path',
              default=DEFAULT_SQLITE_PATH,
              show_default=True,
              help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ SQLite')
def schema(table_name: str, sqlite_path: str):
    """
    Ù†Ù…Ø§ÛŒØ´ schema ÛŒÚ© Ø¬Ø¯ÙˆÙ„

    Ù…Ø«Ø§Ù„:
        python -m gravity_tech.cli.db_commands schema historical_scores
    """
    click.echo(f"ğŸ“ Schema Ø¬Ø¯ÙˆÙ„ '{table_name}':")

    try:
        db_manager = DatabaseManager(sqlite_path=sqlite_path, auto_setup=False)

        schema_info = cast(list[dict[str, Any]], db_manager.get_table_schema(table_name))

        click.echo("\n   Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:")
        for col in schema_info:
            nullable = "NULL" if col.get('nullable', True) else "NOT NULL"
            default = f" DEFAULT {col.get('default')}" if col.get('default') else ""
            click.echo(f"      â€¢ {col['name']}: {col['type']} {nullable}{default}")

    except Exception as e:
        click.echo(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª schema: {_format_db_error(e)}", err=True)
        sys.exit(1)


if __name__ == '__main__':
    db_cli()
