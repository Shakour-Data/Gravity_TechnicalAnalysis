"""
Multi-Horizon Training Pipeline

Pipeline Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø³ÛŒØ³ØªÙ… Ú†Ù†Ø¯ Ø§ÙÙ‚ÛŒ:
1. Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ (Bitcoin)
2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (3d, 7d, 30d)
3. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Multi-Output
4. Ø°Ø®ÛŒØ±Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§
5. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´
"""

import sys
from pathlib import Path
import json
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from typing import List

# Add parent directory to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from gravity_tech.models.schemas import Candle
from gravity_tech.ml.multi_horizon_feature_extraction import MultiHorizonFeatureExtractor
from gravity_tech.ml.multi_horizon_weights import MultiHorizonWeightLearner


def create_realistic_market_data(
    base_price: float = 50000,
    candles_count: int = 500,
    trend: str = "mixed"
) -> List[Candle]:
    """
    Ø³Ø§Ø®Øª Ø¯Ø§Ø¯Ù‡ ÙˆØ§Ù‚Ø¹â€ŒÚ¯Ø±Ø§ÛŒØ§Ù†Ù‡ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
    
    Args:
        base_price: Ù‚ÛŒÙ…Øª Ø´Ø±ÙˆØ¹
        candles_count: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§
        trend: 'bullish', 'bearish', 'mixed'
    """
    candles = []
    base_time = datetime.now() - timedelta(days=candles_count)
    current_price = base_price
    
    for i in range(candles_count):
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø­Ø±Ú©Øª ÙˆØ§Ù‚Ø¹ÛŒ Ù‚ÛŒÙ…Øª
        if trend == "bullish":
            trend_component = i * 10
            volatility = 0.02
        elif trend == "bearish":
            trend_component = -i * 10
            volatility = 0.02
        else:  # mixed
            # ØªØ±Ú©ÛŒØ¨ Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Ø³ÛŒÚ©Ù„
            trend_component = (
                np.sin(i / 30) * 1000 +  # Ø³ÛŒÚ©Ù„ Ú©ÙˆØªØ§Ù‡
                np.sin(i / 100) * 3000 +  # Ø³ÛŒÚ©Ù„ Ù…ÛŒØ§Ù†
                i * 5  # Ø±ÙˆÙ†Ø¯ Ú©Ù„ÛŒ ØµØ¹ÙˆØ¯ÛŒ Ù…Ù„Ø§ÛŒÙ…
            )
            volatility = 0.025
        
        # Ù‚ÛŒÙ…Øª close
        close_price = current_price + trend_component + np.random.normal(0, current_price * volatility)
        
        # high Ùˆ low
        daily_range = abs(np.random.normal(0, current_price * volatility * 1.5))
        high = close_price + daily_range * np.random.uniform(0.3, 0.7)
        low = close_price - daily_range * np.random.uniform(0.3, 0.7)
        
        # open
        if i > 0:
            open_price = candles[-1].close + np.random.normal(0, current_price * volatility * 0.5)
        else:
            open_price = current_price
        
        # volume
        volume = abs(np.random.normal(1000000, 200000))
        
        candle = Candle(
            timestamp=(base_time + timedelta(days=i)).isoformat(),
            open=max(0, open_price),
            high=max(0, high),
            low=max(0, low),
            close=max(0, close_price),
            volume=volume
        )
        
        candles.append(candle)
        current_price = close_price
    
    return candles


def train_multi_horizon_system(
    symbol: str = "BTCUSDT",
    interval: str = "1d",
    lookback_days: int = 365,
    horizons: list = None,
    output_dir: str = "ml_models/multi_horizon"
):
    """
    Ø¢Ù…ÙˆØ²Ø´ Ø³ÛŒØ³ØªÙ… Ú†Ù†Ø¯ Ø§ÙÙ‚ÛŒ
    
    Args:
        symbol: Ù†Ù…Ø§Ø¯ (Ù…Ø«Ù„Ø§Ù‹ BTCUSDT)
        interval: Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ (1d)
        lookback_days: ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ú¯Ø°Ø´ØªÙ‡
        horizons: Ù„ÛŒØ³Øª Ø§ÙÙ‚â€ŒÙ‡Ø§ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: [3, 7, 30])
        output_dir: Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
    """
    horizons = horizons or [3, 7, 30]
    
    print("\n" + "="*70)
    print("ğŸš€ MULTI-HORIZON TRAINING PIPELINE")
    print("="*70)
    print(f"Symbol: {symbol}")
    print(f"Interval: {interval}")
    print(f"Lookback: {lookback_days} days")
    print(f"Horizons: {horizons} days")
    print("="*70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 1: Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š Step 1: Generating market data...")
    
    candles = create_realistic_market_data(
        base_price=50000,
        candles_count=lookback_days + 60,  # Ø§Ø¶Ø§ÙÙ‡ Ø¨Ø±Ø§ÛŒ lookback Ùˆ horizon
        trend="mixed"
    )
    
    print(f"âœ… Generated {len(candles)} candles")
    print(f"   Date range: {candles[0].timestamp} â†’ {candles[-1].timestamp}")
    print(f"   Price range: ${candles[0].close:.2f} â†’ ${candles[-1].close:.2f}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ - Ø³Ø·Ø­ 1 (Indicators)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”¬ Step 2a: Extracting Level 1 Features (Indicators)...")
    
    extractor = MultiHorizonFeatureExtractor(
        lookback_period=100,
        horizons=horizons
    )
    
    X_indicators, Y = extractor.extract_training_dataset(
        candles,
        level="indicators"
    )
    
    print(f"âœ… Level 1 Features: {X_indicators.shape}")
    print(f"   Targets: {Y.shape}")
    
    # Ø¢Ù…Ø§Ø±
    stats_indicators = extractor.create_summary_statistics(X_indicators, Y)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 3: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ - Ø³Ø·Ø­ 1
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ Step 3a: Training Level 1 Model (Indicator Weights)...")
    
    learner_indicators = MultiHorizonWeightLearner(
        horizons=[f'{h}d' for h in horizons],
        test_size=0.2,
        random_state=42
    )
    
    learner_indicators.train(X_indicators, Y, verbose=True)
    
    # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ 1
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    weights_file_l1 = output_path / f"indicator_weights_{symbol.lower()}.json"
    learner_indicators.save_weights(str(weights_file_l1))
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 4: Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ - Ø³Ø·Ø­ 2 (Dimensions)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”¬ Step 4a: Extracting Level 2 Features (Dimensions)...")
    
    X_dimensions, Y_dim = extractor.extract_training_dataset(
        candles,
        level="dimensions"
    )
    
    print(f"âœ… Level 2 Features: {X_dimensions.shape}")
    
    stats_dimensions = extractor.create_summary_statistics(X_dimensions, Y_dim)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 5: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ - Ø³Ø·Ø­ 2
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ Step 5a: Training Level 2 Model (Dimension Weights)...")
    
    learner_dimensions = MultiHorizonWeightLearner(
        horizons=[f'{h}d' for h in horizons],
        test_size=0.2,
        random_state=42
    )
    
    learner_dimensions.train(X_dimensions, Y_dim, verbose=True)
    
    # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ 2
    weights_file_l2 = output_path / f"dimension_weights_{symbol.lower()}.json"
    learner_dimensions.save_weights(str(weights_file_l2))
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 6: Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\n" + "="*70)
    print("ğŸ“‹ FINAL REPORT")
    print("="*70)
    
    # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ Ø³Ø·Ø­
    print("\nğŸ” Level 1 (Indicators) vs Level 2 (Dimensions):")
    print("-" * 70)
    
    summary_l1 = learner_indicators.get_summary()
    summary_l2 = learner_dimensions.get_summary()
    
    for horizon in [f'{h}d' for h in horizons]:
        print(f"\n{horizon.upper()}:")
        
        l1_details = summary_l1['horizon_details'][horizon]
        l2_details = summary_l2['horizon_details'][horizon]
        
        print(f"  Level 1 (Indicators):")
        print(f"    RÂ²:         {l1_details['r2_test']:+.4f}")
        print(f"    MAE:        {l1_details['mae_test']:.4f} ({l1_details['mae_test']*100:.2f}%)")
        print(f"    Confidence: {l1_details['confidence']:.2f}")
        
        print(f"  Level 2 (Dimensions):")
        print(f"    RÂ²:         {l2_details['r2_test']:+.4f}")
        print(f"    MAE:        {l2_details['mae_test']:.4f} ({l2_details['mae_test']*100:.2f}%)")
        print(f"    Confidence: {l2_details['confidence']:.2f}")
        
        # Ø¨Ù‡ØªØ± Ú©Ø¯Ø§Ù…ØŸ
        if l1_details['r2_test'] > l2_details['r2_test']:
            print(f"    âœ… Level 1 performs better (RÂ² difference: {l1_details['r2_test'] - l2_details['r2_test']:+.4f})")
        else:
            print(f"    âœ… Level 2 performs better (RÂ² difference: {l2_details['r2_test'] - l1_details['r2_test']:+.4f})")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 7: Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    config = {
        'symbol': symbol,
        'interval': interval,
        'training_date': datetime.now().isoformat(),
        'lookback_days': lookback_days,
        'horizons': horizons,
        'n_samples': len(X_indicators),
        'level1': {
            'n_features': X_indicators.shape[1],
            'feature_names': list(X_indicators.columns),
            'weights_file': str(weights_file_l1)
        },
        'level2': {
            'n_features': X_dimensions.shape[1],
            'feature_names': list(X_dimensions.columns),
            'weights_file': str(weights_file_l2)
        },
        'statistics': {
            'level1': stats_indicators,
            'level2': stats_dimensions
        }
    }
    
    config_file = output_path / f"config_{symbol.lower()}.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… Configuration saved: {config_file}")
    
    print("\n" + "="*70)
    print("ğŸ‰ TRAINING COMPLETED!")
    print("="*70)
    print(f"Output directory: {output_path}")
    print(f"Files created:")
    print(f"  - {weights_file_l1.name}")
    print(f"  - {weights_file_l2.name}")
    print(f"  - {config_file.name}")
    print("="*70)
    
    return {
        'learner_indicators': learner_indicators,
        'learner_dimensions': learner_dimensions,
        'config': config,
        'output_dir': output_path
    }


def load_trained_model(
    symbol: str = "BTCUSDT",
    level: str = "indicators",  # "indicators" or "dimensions"
    model_dir: str = "ml_models/multi_horizon"
):
    """
    Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡
    
    Args:
        symbol: Ù†Ù…Ø§Ø¯
        level: Ø³Ø·Ø­ (indicators ÛŒØ§ dimensions)
        model_dir: Ù…Ø³ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§
        
    Returns:
        MultiHorizonWeightLearner
    """
    model_path = Path(model_dir)
    
    if level == "indicators":
        weights_file = model_path / f"indicator_weights_{symbol.lower()}.json"
    else:
        weights_file = model_path / f"dimension_weights_{symbol.lower()}.json"
    
    if not weights_file.exists():
        raise FileNotFoundError(f"Weights file not found: {weights_file}")
    
    learner = MultiHorizonWeightLearner()
    learner.load_weights(str(weights_file))
    
    return learner


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI Interface
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Multi-Horizon Training Pipeline"
    )
    parser.add_argument(
        '--symbol',
        type=str,
        default='BTCUSDT',
        help='Trading symbol (default: BTCUSDT)'
    )
    parser.add_argument(
        '--interval',
        type=str,
        default='1d',
        help='Candle interval (default: 1d)'
    )
    parser.add_argument(
        '--lookback',
        type=int,
        default=365,
        help='Lookback days (default: 365)'
    )
    parser.add_argument(
        '--horizons',
        type=int,
        nargs='+',
        default=[3, 7, 30],
        help='Horizons in days (default: 3 7 30)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='ml_models/multi_horizon',
        help='Output directory (default: ml_models/multi_horizon)'
    )
    
    args = parser.parse_args()
    
    # Ø¢Ù…ÙˆØ²Ø´
    result = train_multi_horizon_system(
        symbol=args.symbol,
        interval=args.interval,
        lookback_days=args.lookback,
        horizons=args.horizons,
        output_dir=args.output
    )
    
    print("\nâœ… Training pipeline finished successfully!")
