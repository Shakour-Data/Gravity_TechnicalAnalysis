"""
Training Pipeline Ø¨Ø±Ø§ÛŒ Multi-Horizon Volatility System

Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù†ÙˆØ³Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø³Ù‡ Ø§ÙÙ‚ Ù…Ø³ØªÙ‚Ù„
"""

import numpy as np
import pandas as pd
from typing import Optional, List
import os
from datetime import datetime

from gravity_tech.models.schemas import Candle
from gravity_tech.ml.multi_horizon_volatility_features import MultiHorizonVolatilityFeatureExtractor
from gravity_tech.ml.multi_horizon_weights import MultiHorizonWeightLearner


def create_realistic_volatility_data(
    num_samples: int = 2000,
    volatility_regime: str = 'mixed'  # 'low', 'high', 'mixed', 'squeeze'
) -> List[Candle]:
    """
    Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ Ø±Ú˜ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù†ÙˆØ³Ø§Ù†
    
    Args:
        num_samples: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§
        volatility_regime: Ø±Ú˜ÛŒÙ… Ù†ÙˆØ³Ø§Ù†
            - 'low': Ù†ÙˆØ³Ø§Ù† Ù¾Ø§ÛŒÛŒÙ†
            - 'high': Ù†ÙˆØ³Ø§Ù† Ø¨Ø§Ù„Ø§
            - 'mixed': ØªØ±Ú©ÛŒØ¨ Ø±Ú˜ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
            - 'squeeze': ÙØ´Ø±Ø¯Ú¯ÛŒ Ùˆ Ø´Ú©Ø³Øª
    """
    np.random.seed(42)
    
    dates = pd.date_range(end=pd.Timestamp.now(), periods=num_samples, freq='1h')
    
    base_price = 30000
    prices = [base_price]
    
    candles = []
    
    for i in range(num_samples):
        # ØªØ¹ÛŒÛŒÙ† volatility Ø¨Ø± Ø§Ø³Ø§Ø³ regime
        if volatility_regime == 'low':
            volatility = 0.005  # 0.5%
        elif volatility_regime == 'high':
            volatility = 0.03  # 3%
        elif volatility_regime == 'squeeze':
            # ÙØ´Ø±Ø¯Ú¯ÛŒ Ø¯Ø± Ù†ÛŒÙ…Ù‡ Ø§ÙˆÙ„ØŒ Ø´Ú©Ø³Øª Ø¯Ø± Ù†ÛŒÙ…Ù‡ Ø¯ÙˆÙ…
            if i < num_samples // 2:
                volatility = 0.003  # Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒÛŒÙ†
            else:
                volatility = 0.04  # Ø§Ù†ÙØ¬Ø§Ø± Ù†ÙˆØ³Ø§Ù†
        else:  # mixed
            # ØªØºÛŒÛŒØ± Ø±Ú˜ÛŒÙ… Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù†
            cycle = i % 300
            if cycle < 100:
                volatility = 0.005  # low
            elif cycle < 200:
                volatility = 0.015  # medium
            else:
                volatility = 0.03  # high
        
        # ØªÙˆÙ„ÛŒØ¯ Ù‚ÛŒÙ…Øª
        drift = np.random.normal(0, 0.0005)  # drift Ø®ÛŒÙ„ÛŒ Ú©Ù…
        change = drift + np.random.normal(0, volatility)
        
        if i == 0:
            open_price = base_price
            close_price = base_price * (1 + change)
        else:
            open_price = prices[-1]
            close_price = open_price * (1 + change)
        
        prices.append(close_price)
        
        # High/Low Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ volatility
        high_change = abs(np.random.normal(0, volatility))
        low_change = abs(np.random.normal(0, volatility))
        
        high_price = max(open_price, close_price) * (1 + high_change)
        low_price = min(open_price, close_price) * (1 - low_change)
        
        # Volume
        base_volume = 1000000
        volume = base_volume * (1 + np.random.normal(0, 0.3))
        volume = max(volume, 100000)
        
        # Ø§ÛŒØ¬Ø§Ø¯ Candle
        candle = Candle(
            timestamp=dates[i],
            open=open_price,
            high=high_price,
            low=low_price,
            close=close_price,
            volume=volume
        )
        candles.append(candle)
    
    return candles


def train_volatility_model(
    candles: List[Candle],
    horizons: List[str] = None,
    test_size: float = 0.2,
    output_dir: str = 'models/volatility',
    verbose: bool = True
) -> MultiHorizonWeightLearner:
    """
    Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù†ÙˆØ³Ø§Ù† Ú†Ù†Ø¯ Ø§ÙÙ‚ÛŒ
    
    Args:
        candles: Ù„ÛŒØ³Øª Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§
        horizons: Ù„ÛŒØ³Øª Ø§ÙÙ‚â€ŒÙ‡Ø§ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: ['3d', '7d', '30d'])
        test_size: Ø¯Ø±ØµØ¯ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª
        output_dir: Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
        verbose: Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª
        
    Returns:
        Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
    """
    if horizons is None:
        horizons = ['3d', '7d', '30d']
    
    if verbose:
        print("="*70)
        print("ğŸ¯ TRAINING MULTI-HORIZON VOLATILITY MODEL")
        print("="*70)
        print(f"\nğŸ“Š Dataset: {len(candles)} candles")
        print(f"â±ï¸  Horizons: {horizons}")
        print(f"âœ‚ï¸  Test Size: {test_size:.0%}")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
    if verbose:
        print("\nğŸ” Extracting volatility features...")
    
    extractor = MultiHorizonVolatilityFeatureExtractor(horizons=horizons)
    X, Y = extractor.create_training_dataset(candles, horizons=[int(h.replace('d', '')) for h in horizons])
    
    if verbose:
        print(f"   âœ… Features: {X.shape[1]} columns")
        print(f"   âœ… Samples: {X.shape[0]} rows")
        print(f"   âœ… Targets: {Y.shape[1]} horizons")
        print(f"\n   ğŸ“‹ Feature columns:")
        for i, col in enumerate(X.columns[:5], 1):
            print(f"      {i}. {col}")
        if len(X.columns) > 5:
            print(f"      ... and {len(X.columns) - 5} more")
    
    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    if verbose:
        print("\nğŸ¤– Training models...")
    
    learner = MultiHorizonWeightLearner(
        horizons=horizons,
        test_size=test_size,
        random_state=42,
        lgbm_params={
            'objective': 'regression',
            'metric': 'rmse',
            'verbosity': -1,
            'n_estimators': 150,  # Ø¨ÛŒØ´ØªØ± Ø§Ø² momentum
            'learning_rate': 0.03,  # Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±
            'num_leaves': 31,
            'max_depth': 7,
            'min_child_samples': 20,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'reg_alpha': 0.1,  # L1 regularization
            'reg_lambda': 0.1   # L2 regularization
        }
    )
    
    learner.train(X, Y, verbose=verbose)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
    os.makedirs(output_dir, exist_ok=True)
    model_path = os.path.join(output_dir, 'volatility_weights.json')
    learner.save_weights(model_path)
    
    if verbose:
        print(f"\nğŸ’¾ Model saved: {model_path}")
    
    # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
    if verbose:
        print("\n" + "="*70)
        print("ğŸ“ˆ TRAINING RESULTS")
        print("="*70)
        
        for horizon in horizons:
            weights_info = learner.get_horizon_weights(horizon)
            print(f"\n{horizon.upper()}:")
            print(f"  RÂ² Score:   {weights_info.metrics['r2_score']:.3f}")
            print(f"  MAE:        {weights_info.metrics['mae']:.4f}")
            print(f"  RMSE:       {weights_info.metrics['rmse']:.4f}")
            print(f"  Confidence: {weights_info.confidence:.2f}")
            
            # Ù†Ù…Ø§ÛŒØ´ top features
            top_features = sorted(
                weights_info.weights.items(),
                key=lambda x: abs(x[1]),
                reverse=True
            )[:5]
            
            print(f"\n  ğŸ” Top 5 Features:")
            for feat, weight in top_features:
                print(f"     {feat:30s}: {weight:+.4f}")
    
    # ØªØ­Ù„ÛŒÙ„ Ø§Ù‡Ù…ÛŒØª Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§
    if verbose:
        print("\n" + "="*70)
        print("ğŸ“Š INDICATOR IMPORTANCE ANALYSIS")
        print("="*70)
        
        indicators = [
            'atr', 'bollinger_bands', 'keltner_channel', 'donchian_channel',
            'standard_deviation', 'historical_volatility', 'atr_percentage', 'chaikin_volatility'
        ]
        
        for horizon in horizons:
            weights_info = learner.get_horizon_weights(horizon)
            
            print(f"\n{horizon.upper()}:")
            indicator_importance = {}
            
            for indicator in indicators:
                # Ø¬Ù…Ø¹ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ absolute Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±
                indicator_weights = [
                    abs(weight) for feat, weight in weights_info.weights.items()
                    if feat.startswith(indicator)
                ]
                if indicator_weights:
                    indicator_importance[indicator] = sum(indicator_weights) / len(indicator_weights)
            
            # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
            sorted_importance = sorted(
                indicator_importance.items(),
                key=lambda x: x[1],
                reverse=True
            )
            
            for indicator, importance in sorted_importance:
                bar = "â–ˆ" * int(importance * 50)
                print(f"  {indicator:25s}: {bar} {importance:.3f}")
    
    return learner


def main():
    """
    Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ pipeline Ø¢Ù…ÙˆØ²Ø´
    """
    print("\n" + "="*70)
    print("ğŸš€ VOLATILITY MODEL TRAINING PIPELINE")
    print("="*70)
    
    # 1. Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ
    print("\nğŸ“¦ Creating training data...")
    print("   Generating mixed volatility regime data...")
    
    candles = create_realistic_volatility_data(
        num_samples=2000,
        volatility_regime='mixed'
    )
    
    print(f"   âœ… Generated {len(candles)} candles")
    print(f"   ğŸ“… Date range: {candles[0].timestamp} to {candles[-1].timestamp}")
    
    # Ø¢Ù…Ø§Ø± Ø§ÙˆÙ„ÛŒÙ‡
    closes = [c.close for c in candles]
    print(f"\n   ğŸ“Š Price statistics:")
    print(f"      Min:  ${min(closes):,.2f}")
    print(f"      Max:  ${max(closes):,.2f}")
    print(f"      Mean: ${np.mean(closes):,.2f}")
    print(f"      Std:  ${np.std(closes):,.2f}")
    
    # 2. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    print("\n" + "="*70)
    learner = train_volatility_model(
        candles=candles,
        horizons=['3d', '7d', '30d'],
        test_size=0.2,
        output_dir='models/volatility',
        verbose=True
    )
    
    # 3. ØªØ³Øª Ù…Ø¯Ù„
    print("\n" + "="*70)
    print("ğŸ§ª TESTING MODEL ON RECENT DATA")
    print("="*70)
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø§Ø¯Ù‡
    extractor = MultiHorizonVolatilityFeatureExtractor()
    features = extractor.extract_volatility_features(candles)
    
    print("\nğŸ“Š Sample features:")
    for i, (key, value) in enumerate(list(features.items())[:5], 1):
        print(f"   {i}. {key:30s}: {value:.4f}")
    
    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    X_test = pd.DataFrame([features])
    predictions = learner.predict_multi_horizon(X_test)
    
    print("\nğŸ¯ Predictions:")
    for horizon in ['3d', '7d', '30d']:
        pred_value = predictions[f'pred_{horizon}'].iloc[0]
        print(f"   {horizon}: {pred_value:+.4f} ({'Ø§ÙØ²Ø§ÛŒØ´ Ù†ÙˆØ³Ø§Ù†' if pred_value > 0 else 'Ú©Ø§Ù‡Ø´ Ù†ÙˆØ³Ø§Ù†'})")
    
    print("\n" + "="*70)
    print("âœ… TRAINING COMPLETED SUCCESSFULLY")
    print("="*70)
    print("\nğŸ’¡ Next steps:")
    print("   1. Test the model with real market data")
    print("   2. Integrate with MultiHorizonVolatilityAnalyzer")
    print("   3. Compare predictions with actual volatility changes")
    print("   4. Fine-tune hyperparameters if needed")
    print()


if __name__ == '__main__':
    main()
