"""
Multi-Horizon Feature Extraction for ML Weight Learning

Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¯Ø± Ú†Ù†Ø¯ÛŒÙ† Ø§ÙÙ‚ Ø²Ù…Ø§Ù†ÛŒ:
- 3 Ø±ÙˆØ² (Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª - Day Trading)
- 7 Ø±ÙˆØ² (Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª - Swing Trading)
- 30 Ø±ÙˆØ² (Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª - Position Trading)
"""


import pandas as pd
from gravity_tech.core.domain.entities import Candle
from gravity_tech.core.indicators.trend import TrendIndicators
from gravity_tech.patterns.candlestick import CandlestickPatterns
from gravity_tech.patterns.classical import ClassicalPatterns
from gravity_tech.patterns.elliott_wave import ElliottWaveAnalyzer


class MultiHorizonFeatureExtractor:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† Ø§ÙÙ‚ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    """

    # Ø§ÙÙ‚â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ (Ø±ÙˆØ²)
    HORIZONS = [3, 7, 30]

    def __init__(
        self,
        lookback_period: int = 100,
        horizons: list = None
    ):
        """
        Initialize multi-horizon feature extractor

        Args:
            lookback_period: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§
            horizons: Ù„ÛŒØ³Øª Ø§ÙÙ‚â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: [3, 7, 30])
                     Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ int Ø¨Ø§Ø´Ø¯ [3, 7, 30] ÛŒØ§ string ['3d', '7d', '30d']
        """
        self.lookback_period = lookback_period
        # ØªØ¨Ø¯ÛŒÙ„ robust horizons Ø¨Ù‡ int (Ø­ØªÛŒ Ø§Ú¯Ø± ÙˆØ±ÙˆØ¯ÛŒ ['3d', ...] ÛŒØ§ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§Ø´Ø¯)
        def _to_int_horizon(h):
            if isinstance(h, str):
                return int(h.lower().replace('d','').strip())
            return int(h)
        if horizons is None:
            self.horizons = self.HORIZONS
        else:
            self.horizons = [_to_int_horizon(h) for h in horizons]
        # Ø­Ø¯Ø§Ú©Ø«Ø± Ø§ÙÙ‚ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª
        self.max_horizon = max(self.horizons)

    def extract_indicator_features(
        self,
        candles: list[Candle]
    ) -> dict[str, float]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ (Ø³Ø·Ø­ 1)

        Returns:
            21 ÙˆÛŒÚ˜Ú¯ÛŒ Ø§Ø² 7 Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± (signal, confidence, weighted)
        """
        if len(candles) < self.lookback_period:
            raise ValueError(f"Need at least {self.lookback_period} candles")

        # 7 Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± Ù…ÙˆØ¬ÙˆØ¯
        indicators = {
            'sma': TrendIndicators.sma(candles, period=20),
            'ema': TrendIndicators.ema(candles, period=20),
            'wma': TrendIndicators.wma(candles, period=20),
            'dema': TrendIndicators.dema(candles, period=20),
            'tema': TrendIndicators.tema(candles, period=20),
            'macd': TrendIndicators.macd(candles),
            'adx': TrendIndicators.adx(candles)
        }

        features = {}

        for name, result in indicators.items():
            # Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡ [-1, 1]
            signal_score = result.signal.get_score() / 2.0

            features[f'{name}_signal'] = signal_score
            features[f'{name}_confidence'] = result.confidence
            features[f'{name}_weighted'] = signal_score * result.confidence

        return features

    def extract_dimension_features(
        self,
        candles: list[Candle]
    ) -> dict[str, float]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ 4 Ø¨ÙØ¹Ø¯ (Ø³Ø·Ø­ 2)

        Returns:
            12 ÙˆÛŒÚ˜Ú¯ÛŒ Ø§Ø² 4 Ø¨ÙØ¹Ø¯ (score, confidence, weighted)
        """
        if len(candles) < self.lookback_period:
            raise ValueError(f"Need at least {self.lookback_period} candles")

        features = {}

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ø¨ÙØ¹Ø¯ 1: Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            indicator_results = [
                TrendIndicators.sma(candles, 20),
                TrendIndicators.ema(candles, 20),
                TrendIndicators.wma(candles, 20),
                TrendIndicators.dema(candles, 20),
                TrendIndicators.tema(candles, 20),
                TrendIndicators.macd(candles),
                TrendIndicators.adx(candles)
            ]

            weighted_sum = sum(ind.signal.get_score() * ind.confidence for ind in indicator_results)
            total_weight = sum(ind.confidence for ind in indicator_results)

            dim1_score = weighted_sum / total_weight if total_weight > 0 else 0.0
            dim1_confidence = total_weight / len(indicator_results)

        except Exception as e:
            print(f"Warning: Indicator calculation error: {e}")
            dim1_score = 0.0
            dim1_confidence = 0.5

        features['dim1_indicators_score'] = dim1_score / 2.0  # Ù†Ø±Ù…Ø§Ù„ Ø¨Ù‡ [-1, 1]
        features['dim1_indicators_confidence'] = dim1_confidence
        features['dim1_indicators_weighted'] = (dim1_score / 2.0) * dim1_confidence

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ø¨ÙØ¹Ø¯ 2: Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            patterns = CandlestickPatterns.detect_patterns(candles[-10:])

            if patterns:
                # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„ Ùˆ Ø§Ø¹ØªÙ…Ø§Ø¯
                avg_signal = sum(p.signal.get_score() for p in patterns) / len(patterns)
                avg_confidence = sum(p.confidence for p in patterns) / len(patterns)

                dim2_score = avg_signal / 2.0
                dim2_confidence = avg_confidence
            else:
                dim2_score = 0.0
                dim2_confidence = 0.5

        except Exception as e:
            print(f"Warning: Candlestick pattern error: {e}")
            dim2_score = 0.0
            dim2_confidence = 0.5

        features['dim2_candlestick_score'] = dim2_score
        features['dim2_candlestick_confidence'] = dim2_confidence
        features['dim2_candlestick_weighted'] = dim2_score * dim2_confidence

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ø¨ÙØ¹Ø¯ 3: Ø§Ù…ÙˆØ§Ø¬ Ø§Ù„ÛŒÙˆØª
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            elliott = ElliottWaveAnalyzer.analyze(candles)

            dim3_score = elliott.signal.get_score() / 2.0
            dim3_confidence = elliott.confidence

        except Exception as e:
            print(f"Warning: Elliott Wave error: {e}")
            dim3_score = 0.0
            dim3_confidence = 0.5

        features['dim3_elliott_score'] = dim3_score
        features['dim3_elliott_confidence'] = dim3_confidence
        features['dim3_elliott_weighted'] = dim3_score * dim3_confidence

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ø¨ÙØ¹Ø¯ 4: Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ©
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            classical = ClassicalPatterns.detect_all(candles)

            if classical:
                avg_signal = sum(p.signal.get_score() for p in classical) / len(classical)
                avg_confidence = sum(p.confidence for p in classical) / len(classical)

                dim4_score = avg_signal / 2.0
                dim4_confidence = avg_confidence
            else:
                dim4_score = 0.0
                dim4_confidence = 0.5

        except Exception as e:
            print(f"Warning: Classical pattern error: {e}")
            dim4_score = 0.0
            dim4_confidence = 0.5

        features['dim4_classical_score'] = dim4_score
        features['dim4_classical_confidence'] = dim4_confidence
        features['dim4_classical_weighted'] = dim4_score * dim4_confidence

        return features

    def calculate_multi_horizon_returns(
        self,
        candles: list[Candle],
        current_idx: int
    ) -> dict[str, float]:
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ø¯Ù‡ÛŒ Ø¨Ø±Ø§ÛŒ Ú†Ù†Ø¯ÛŒÙ† Ø§ÙÙ‚ Ø²Ù…Ø§Ù†ÛŒ

        Returns:
            {
                'return_3d': 0.025,   # 2.5%
                'return_7d': 0.058,   # 5.8%
                'return_30d': 0.152   # 15.2%
            }
        """
        # Validate current candle
        current_candle = candles[current_idx]
        if not isinstance(current_candle, Candle):
            raise TypeError(f"Expected Candle at index {current_idx}, got {type(current_candle)}")

        current_price = current_candle.close
        returns = {}

        for horizon in self.horizons:
            future_idx = current_idx + horizon

            if future_idx < len(candles):
                future_candle = candles[future_idx]
                # Validate future candle
                if not isinstance(future_candle, Candle):
                    raise TypeError(f"Expected Candle at index {future_idx}, got {type(future_candle)}")
                future_price = future_candle.close
                return_pct = (future_price - current_price) / current_price
                returns[f'return_{horizon}d'] = return_pct
            else:
                # Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª
                returns[f'return_{horizon}d'] = None

        return returns

    def extract_training_dataset(
        self,
        candles: list[Candle],
        level: str = "indicators"  # "indicators" or "dimensions"
    ) -> tuple[pd.DataFrame, pd.DataFrame]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÛŒØªØ§Ø³Øª Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† Ù‡Ø¯Ù

        Args:
            candles: Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ
            level: Ø³Ø·Ø­ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (indicators ÛŒØ§ dimensions)

        Returns:
            X: DataFrame ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
            Y: DataFrame Ø§Ù‡Ø¯Ø§Ù (Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ return_3d, return_7d, return_30d)
        """
        print(f"\nğŸ“Š Extracting multi-horizon features at '{level}' level...")
        print(f"   Horizons: {self.horizons} days")

        all_features = []
        all_targets = []

        # Ø­Ù„Ù‚Ù‡ Ø±ÙˆÛŒ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§
        for i in range(len(candles) - self.lookback_period - self.max_horizon):
            # Ù¾Ù†Ø¬Ø±Ù‡ lookback
            window = candles[i : i + self.lookback_period]

            try:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
                if level == "indicators":
                    features = self.extract_indicator_features(window)
                elif level == "dimensions":
                    features = self.extract_dimension_features(window)
                else:
                    raise ValueError(f"Unknown level: {level}")

                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ø¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡
                targets = self.calculate_multi_horizon_returns(
                    candles,
                    i + self.lookback_period
                )

                # ÙÙ‚Ø· Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„
                if None not in targets.values():
                    all_features.append(features)
                    all_targets.append(targets)

            except Exception as e:
                print(f"Warning: Error processing sample {i}: {e}")
                continue

        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
        X = pd.DataFrame(all_features)
        Y = pd.DataFrame(all_targets)

        print(f"âœ… Extracted {len(X)} complete training samples")
        print(f"   Features: {X.shape[1]} columns")
        print(f"   Targets: {Y.shape[1]} horizons")

        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø¨Ø§Ø²Ø¯Ù‡ÛŒâ€ŒÙ‡Ø§
        for horizon in self.horizons:
            col = f'return_{horizon}d'
            mean_return = Y[col].mean()
            std_return = Y[col].std()
            print(f"   {col}: mean={mean_return:.4f} ({mean_return*100:.2f}%), std={std_return:.4f}")

        return X, Y

    def create_summary_statistics(
        self,
        X: pd.DataFrame,
        Y: pd.DataFrame
    ) -> dict:
        """
        Ø¢Ù…Ø§Ø± Ø®Ù„Ø§ØµÙ‡ Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª
        """
        return {
            'n_samples': len(X),
            'n_features': X.shape[1],
            'n_horizons': Y.shape[1],
            'horizons': self.horizons,
            'feature_names': list(X.columns),
            'target_statistics': {
                f'return_{h}d': {
                    'mean': Y[f'return_{h}d'].mean(),
                    'std': Y[f'return_{h}d'].std(),
                    'min': Y[f'return_{h}d'].min(),
                    'max': Y[f'return_{h}d'].max(),
                    'positive_ratio': (Y[f'return_{h}d'] > 0).mean()
                }
                for h in self.horizons
            }
        }
