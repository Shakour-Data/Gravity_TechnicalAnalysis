"""
Training Pipeline for Multi-Horizon Support/Resistance Weights

Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ ML Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Support & Resistance Ø¢Ù…ÙˆØ²Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡:
1. Bounce Scenario: Ù‚ÛŒÙ…Øª Ø§Ø² Ø³Ø·Ø­ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯
2. Breakout Scenario: Ù‚ÛŒÙ…Øª Ø³Ø·Ø­ Ø±Ø§ Ù…ÛŒâ€ŒØ´Ú©Ù†Ø¯
3. Fake-out Scenario: Ø´Ú©Ø³Øª Ù…ÙˆÙ‚Øª Ùˆ Ø¨Ø±Ú¯Ø´Øª
4. Consolidation: Ù†ÙˆØ³Ø§Ù† Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡
"""

import numpy as np
import pandas as pd
from typing import List, Dict, Tuple
import json
from pathlib import Path
from datetime import datetime, timedelta

from gravity_tech.models.schemas import Candle
from gravity_tech.ml.multi_horizon_support_resistance_features import MultiHorizonSupportResistanceFeatureExtractor
from gravity_tech.ml.multi_horizon_support_resistance_analysis import MultiHorizonSupportResistanceAnalyzer


def create_bounce_scenario(
    base_price: float = 50000,
    num_candles: int = 100
) -> Tuple[List[Candle], float]:
    """
    Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø§Ø±ÛŒÙˆ Bounce (Ø¨Ø±Ú¯Ø´Øª Ø§Ø² Ø­Ù…Ø§ÛŒØª/Ù…Ù‚Ø§ÙˆÙ…Øª)
    
    Returns:
        (candles, target_score)
        target_score: +1 for bounce from support, -1 for bounce from resistance
    """
    candles = []
    start_time = datetime.now() - timedelta(hours=num_candles)
    
    # Ø§Ù†ØªØ®Ø§Ø¨ bounce Ø§Ø² support ÛŒØ§ resistance
    bounce_from_support = np.random.random() > 0.5
    
    if bounce_from_support:
        # Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ø³Ù…Øª Ù¾Ø§ÛŒÛŒÙ† Ù…ÛŒâ€ŒØ±ÙˆØ¯ (Ø¨Ù‡ Ø³Ù…Øª support)
        trend_direction = -1
        target_score = 1.0  # Ù…ÙˆÙ‚Ø¹ÛŒØª Ø®ÙˆØ¨ Ø¨Ø±Ø§ÛŒ Ø®Ø±ÛŒØ¯
    else:
        # Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ø³Ù…Øª Ø¨Ø§Ù„Ø§ Ù…ÛŒâ€ŒØ±ÙˆØ¯ (Ø¨Ù‡ Ø³Ù…Øª resistance)
        trend_direction = 1
        target_score = -1.0  # Ù…ÙˆÙ‚Ø¹ÛŒØª Ø®ÙˆØ¨ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´
    
    # Ù…Ø±Ø­Ù„Ù‡ 1: Ø­Ø±Ú©Øª Ø¨Ù‡ Ø³Ù…Øª Ø³Ø·Ø­ (70% Ø§Ø² Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§)
    approach_candles = int(num_candles * 0.7)
    price = base_price
    
    for i in range(approach_candles):
        # Ø­Ø±Ú©Øª ØªØ¯Ø±ÛŒØ¬ÛŒ Ø¨Ù‡ Ø³Ù…Øª Ø³Ø·Ø­
        trend = trend_direction * base_price * 0.002 * (1 + i / approach_candles)
        volatility = np.random.normal(0, base_price * 0.005)
        
        price += trend + volatility
        
        high = price * (1 + abs(np.random.normal(0, 0.003)))
        low = price * (1 - abs(np.random.normal(0, 0.003)))
        close = np.random.uniform(low, high)
        
        candle = Candle(
            timestamp=start_time + timedelta(hours=i),
            open=price,
            high=high,
            low=low,
            close=close,
            volume=np.random.uniform(1000, 2000)
        )
        candles.append(candle)
        price = close
    
    # Ù…Ø±Ø­Ù„Ù‡ 2: bounce Ø§Ø² Ø³Ø·Ø­ (30% Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡)
    bounce_candles = num_candles - approach_candles
    bounce_strength = 0.015  # 1.5% bounce
    
    for i in range(bounce_candles):
        # Ø¨Ø±Ú¯Ø´Øª Ù‚ÙˆÛŒ Ø§Ø² Ø³Ø·Ø­
        trend = -trend_direction * base_price * bounce_strength * (1 - i / bounce_candles)
        volatility = np.random.normal(0, base_price * 0.003)
        
        price += trend + volatility
        
        high = price * (1 + abs(np.random.normal(0, 0.003)))
        low = price * (1 - abs(np.random.normal(0, 0.003)))
        close = np.random.uniform(low, high)
        
        # Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ Ø¯Ø± bounce
        volume = np.random.uniform(1500, 3000)
        
        candle = Candle(
            timestamp=start_time + timedelta(hours=approach_candles + i),
            open=price,
            high=high,
            low=low,
            close=close,
            volume=volume
        )
        candles.append(candle)
        price = close
    
    return candles, target_score


def create_breakout_scenario(
    base_price: float = 50000,
    num_candles: int = 100
) -> Tuple[List[Candle], float]:
    """
    Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø§Ø±ÛŒÙˆ Breakout (Ø´Ú©Ø³Øª Ø³Ø·Ø­)
    
    Returns:
        (candles, target_score)
        target_score: 0.0 (Ø³Ø·Ø­ Ø´Ú©Ø³ØªÙ‡ Ø´Ø¯Ù‡ØŒ Ø¯ÛŒÚ¯Ø± Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª)
    """
    candles = []
    start_time = datetime.now() - timedelta(hours=num_candles)
    
    # Ø§Ù†ØªØ®Ø§Ø¨ breakout Ø¨Ù‡ Ø¨Ø§Ù„Ø§ ÛŒØ§ Ù¾Ø§ÛŒÛŒÙ†
    breakout_up = np.random.random() > 0.5
    
    if breakout_up:
        trend_direction = 1
        target_score = 0.3  # Ø¨Ø¹Ø¯ Ø§Ø² Ø´Ú©Ø³Øª Ù…Ù‚Ø§ÙˆÙ…ØªØŒ Ø§Ø¯Ø§Ù…Ù‡ ØµØ¹ÙˆØ¯
    else:
        trend_direction = -1
        target_score = -0.3  # Ø¨Ø¹Ø¯ Ø§Ø² Ø´Ú©Ø³Øª Ø­Ù…Ø§ÛŒØªØŒ Ø§Ø¯Ø§Ù…Ù‡ Ù†Ø²ÙˆÙ„
    
    # Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ³Øª Ú†Ù†Ø¯Ø¨Ø§Ø±Ù‡ Ø³Ø·Ø­ (60% Ø§Ø² Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§)
    test_candles = int(num_candles * 0.6)
    price = base_price
    
    for i in range(test_candles):
        # Ù†ÙˆØ³Ø§Ù† Ø¯Ø± Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø³Ø·Ø­ (consolidation)
        if i % 10 < 7:  # 70% ÙˆÙ‚Øª Ù†Ø²Ø¯ÛŒÚ© Ø³Ø·Ø­
            movement = np.random.normal(0, base_price * 0.003)
        else:  # 30% ÙˆÙ‚Øª ØªØ³Øª Ø³Ø·Ø­
            movement = trend_direction * base_price * 0.005
        
        price += movement
        
        high = price * (1 + abs(np.random.normal(0, 0.003)))
        low = price * (1 - abs(np.random.normal(0, 0.003)))
        close = np.random.uniform(low, high)
        
        candle = Candle(
            timestamp=start_time + timedelta(hours=i),
            open=price,
            high=high,
            low=low,
            close=close,
            volume=np.random.uniform(1000, 1500)
        )
        candles.append(candle)
        price = close
    
    # Ù…Ø±Ø­Ù„Ù‡ 2: Ø´Ú©Ø³Øª Ø³Ø·Ø­ (40% Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡)
    breakout_candles = num_candles - test_candles
    
    for i in range(breakout_candles):
        # Ø­Ø±Ú©Øª Ù‚ÙˆÛŒ Ø¯Ø± Ø¬Ù‡Øª Ø´Ú©Ø³Øª
        trend = trend_direction * base_price * 0.02 * (1 + i / breakout_candles)
        volatility = np.random.normal(0, base_price * 0.004)
        
        price += trend + volatility
        
        high = price * (1 + abs(np.random.normal(0, 0.004)))
        low = price * (1 - abs(np.random.normal(0, 0.004)))
        close = np.random.uniform(low, high)
        
        # Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ Ø¯Ø± breakout
        volume = np.random.uniform(2000, 4000)
        
        candle = Candle(
            timestamp=start_time + timedelta(hours=test_candles + i),
            open=price,
            high=high,
            low=low,
            close=close,
            volume=volume
        )
        candles.append(candle)
        price = close
    
    return candles, target_score


def create_consolidation_scenario(
    base_price: float = 50000,
    num_candles: int = 100
) -> Tuple[List[Candle], float]:
    """
    Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø§Ø±ÛŒÙˆ Consolidation (Ù†ÙˆØ³Ø§Ù† Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡)
    
    Returns:
        (candles, target_score)
        target_score: 0.0 (Ø®Ù†Ø«ÛŒ)
    """
    candles = []
    start_time = datetime.now() - timedelta(hours=num_candles)
    
    # ØªØ¹Ø±ÛŒÙ Ù…Ø­Ø¯ÙˆØ¯Ù‡
    range_size = base_price * 0.04  # 4% range
    support = base_price - range_size / 2
    resistance = base_price + range_size / 2
    
    price = base_price
    
    for i in range(num_candles):
        # Ù†ÙˆØ³Ø§Ù† Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ support-resistance
        # ØªÙ…Ø§ÛŒÙ„ Ø¨Ù‡ Ø¨Ø±Ú¯Ø´Øª Ø§Ø² Ø­Ø¯ range
        if price < support + range_size * 0.2:
            bias = 1  # ÙØ´Ø§Ø± Ø¨Ù‡ Ø³Ù…Øª Ø¨Ø§Ù„Ø§
        elif price > resistance - range_size * 0.2:
            bias = -1  # ÙØ´Ø§Ø± Ø¨Ù‡ Ø³Ù…Øª Ù¾Ø§ÛŒÛŒÙ†
        else:
            bias = 0  # Ø®Ù†Ø«ÛŒ
        
        movement = bias * base_price * 0.003 + np.random.normal(0, base_price * 0.005)
        price += movement
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ range
        price = np.clip(price, support * 0.99, resistance * 1.01)
        
        high = min(price * (1 + abs(np.random.normal(0, 0.003))), resistance * 1.005)
        low = max(price * (1 - abs(np.random.normal(0, 0.003))), support * 0.995)
        close = np.random.uniform(low, high)
        
        candle = Candle(
            timestamp=start_time + timedelta(hours=i),
            open=price,
            high=high,
            low=low,
            close=close,
            volume=np.random.uniform(800, 1200)
        )
        candles.append(candle)
        price = close
    
    target_score = 0.0  # Ø®Ù†Ø«ÛŒ
    return candles, target_score


def create_fake_out_scenario(
    base_price: float = 50000,
    num_candles: int = 100
) -> Tuple[List[Candle], float]:
    """
    Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø§Ø±ÛŒÙˆ Fake-out (Ø´Ú©Ø³Øª Ù…ÙˆÙ‚Øª Ùˆ Ø¨Ø±Ú¯Ø´Øª)
    
    Returns:
        (candles, target_score)
        target_score: Ù…Ø¹Ú©ÙˆØ³ Ø¬Ù‡Øª fake-out
    """
    candles = []
    start_time = datetime.now() - timedelta(hours=num_candles)
    
    # Ø§Ù†ØªØ®Ø§Ø¨ fake-out Ø¨Ù‡ Ø¨Ø§Ù„Ø§ ÛŒØ§ Ù¾Ø§ÛŒÛŒÙ†
    fake_up = np.random.random() > 0.5
    
    if fake_up:
        initial_direction = 1
        final_direction = -1
        target_score = -0.7  # fake breakout Ø¨Ø§Ù„Ø§ â†’ ÙØ±ÙˆØ´
    else:
        initial_direction = -1
        final_direction = 1
        target_score = 0.7  # fake breakdown Ù¾Ø§ÛŒÛŒÙ† â†’ Ø®Ø±ÛŒØ¯
    
    # Ù…Ø±Ø­Ù„Ù‡ 1: Ù†Ø²Ø¯ÛŒÚ© Ø´Ø¯Ù† Ø¨Ù‡ Ø³Ø·Ø­ (40%)
    approach_candles = int(num_candles * 0.4)
    price = base_price
    
    for i in range(approach_candles):
        trend = initial_direction * base_price * 0.001
        volatility = np.random.normal(0, base_price * 0.003)
        price += trend + volatility
        
        high = price * (1 + abs(np.random.normal(0, 0.003)))
        low = price * (1 - abs(np.random.normal(0, 0.003)))
        close = np.random.uniform(low, high)
        
        candle = Candle(
            timestamp=start_time + timedelta(hours=i),
            open=price,
            high=high,
            low=low,
            close=close,
            volume=np.random.uniform(1000, 1500)
        )
        candles.append(candle)
        price = close
    
    # Ù…Ø±Ø­Ù„Ù‡ 2: fake breakout (20%)
    fake_candles = int(num_candles * 0.2)
    
    for i in range(fake_candles):
        trend = initial_direction * base_price * 0.015
        volatility = np.random.normal(0, base_price * 0.002)
        price += trend + volatility
        
        high = price * (1 + abs(np.random.normal(0, 0.004)))
        low = price * (1 - abs(np.random.normal(0, 0.004)))
        close = np.random.uniform(low, high)
        
        # Ø­Ø¬Ù… Ù…ØªÙˆØ³Ø· (Ù†Ù‡ Ø®ÛŒÙ„ÛŒ Ø¨Ø§Ù„Ø§ - Ù†Ø´Ø§Ù†Ù‡ fake)
        volume = np.random.uniform(1200, 1800)
        
        candle = Candle(
            timestamp=start_time + timedelta(hours=approach_candles + i),
            open=price,
            high=high,
            low=low,
            close=close,
            volume=volume
        )
        candles.append(candle)
        price = close
    
    # Ù…Ø±Ø­Ù„Ù‡ 3: Ø¨Ø±Ú¯Ø´Øª Ù‚ÙˆÛŒ (40%)
    reversal_candles = num_candles - approach_candles - fake_candles
    
    for i in range(reversal_candles):
        trend = final_direction * base_price * 0.02 * (1 + i / reversal_candles)
        volatility = np.random.normal(0, base_price * 0.004)
        price += trend + volatility
        
        high = price * (1 + abs(np.random.normal(0, 0.005)))
        low = price * (1 - abs(np.random.normal(0, 0.005)))
        close = np.random.uniform(low, high)
        
        # Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ Ø¯Ø± reversal
        volume = np.random.uniform(2000, 3500)
        
        candle = Candle(
            timestamp=start_time + timedelta(hours=approach_candles + fake_candles + i),
            open=price,
            high=high,
            low=low,
            close=close,
            volume=volume
        )
        candles.append(candle)
        price = close
    
    return candles, target_score


class MultiHorizonSupportResistanceTrainer:
    """Trainer Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Support & Resistance"""
    
    def __init__(self):
        """Initialize trainer"""
        self.feature_extractor = MultiHorizonSupportResistanceFeatureExtractor()
    
    def prepare_training_data(
        self,
        num_samples: int = 2000
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ Ø¢Ù…ÙˆØ²Ø´
        
        Args:
            num_samples: ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ (500 Ø§Ø² Ù‡Ø± Ø³Ù†Ø§Ø±ÛŒÙˆ)
            
        Returns:
            (features_df, targets_df)
        """
        print(f"ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ {num_samples} Ù†Ù…ÙˆÙ†Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ...")
        
        all_features = []
        all_targets = []
        
        samples_per_scenario = num_samples // 4
        
        scenarios = [
            ('bounce', create_bounce_scenario),
            ('breakout', create_breakout_scenario),
            ('consolidation', create_consolidation_scenario),
            ('fake_out', create_fake_out_scenario)
        ]
        
        for scenario_name, scenario_func in scenarios:
            print(f"  ğŸ“Š ØªÙˆÙ„ÛŒØ¯ {samples_per_scenario} Ù†Ù…ÙˆÙ†Ù‡ {scenario_name}...")
            
            for i in range(samples_per_scenario):
                # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡
                base_price = np.random.uniform(30000, 70000)
                num_candles = np.random.randint(80, 120)
                
                candles, target_score = scenario_func(base_price, num_candles)
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø§ÙÙ‚â€ŒÙ‡Ø§
                try:
                    features = self.feature_extractor.extract_all_horizons(candles)
                    
                    # Target Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø§ÙÙ‚
                    targets = {
                        '3d_target': target_score,
                        '7d_target': target_score * 0.9,  # Ú©Ù…ÛŒ Ù…Ù„Ø§ÛŒÙ…â€ŒØªØ±
                        '30d_target': target_score * 0.7,  # Ø®ÛŒÙ„ÛŒ Ù…Ù„Ø§ÛŒÙ…â€ŒØªØ±
                        'scenario': scenario_name
                    }
                    
                    all_features.append(features)
                    all_targets.append(targets)
                    
                except Exception as e:
                    print(f"    âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…ÙˆÙ†Ù‡ {i}: {e}")
                    continue
        
        features_df = pd.DataFrame(all_features)
        targets_df = pd.DataFrame(all_targets)
        
        print(f"âœ… ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ù…Ù„ Ø´Ø¯: {len(features_df)} Ù†Ù…ÙˆÙ†Ù‡")
        print(f"   ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {len(features_df.columns)} Ø³ØªÙˆÙ†")
        
        return features_df, targets_df
    
    def train(
        self,
        features_df: pd.DataFrame,
        targets_df: pd.DataFrame,
        output_path: str = "models/support_resistance/sr_weights.json"
    ):
        """
        Ø¢Ù…ÙˆØ²Ø´ ÙˆØ²Ù†â€ŒÙ‡Ø§
        
        Args:
            features_df: DataFrame ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
            targets_df: DataFrame target Ù‡Ø§
            output_path: Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§
        """
        print("\nğŸ¯ Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ ÙˆØ²Ù†â€ŒÙ‡Ø§...")
        
        weights = {}
        
        for horizon in ['3d', '7d', '30d']:
            print(f"\n  ğŸ“Š Ø¢Ù…ÙˆØ²Ø´ {horizon}...")
            
            # Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§ÛŒÙ† Ø§ÙÙ‚
            horizon_features = [col for col in features_df.columns if col.startswith(f'{horizon}_')]
            X = features_df[horizon_features].values
            y = targets_df[f'{horizon}_target'].values
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¨Ø§ Linear Regression Ø³Ø§Ø¯Ù‡
            # X.T @ X @ weights = X.T @ y
            # weights = (X.T @ X)^-1 @ X.T @ y
            
            try:
                XTX = X.T @ X
                XTy = X.T @ y
                
                # Ø§ÙØ²ÙˆØ¯Ù† regularization Ú©ÙˆÚ†Ú©
                reg = 0.01
                XTX_reg = XTX + reg * np.eye(XTX.shape[0])
                
                w = np.linalg.solve(XTX_reg, XTy)
                
                # Ø§ÛŒØ¬Ø§Ø¯ dictionary ÙˆØ²Ù†â€ŒÙ‡Ø§
                horizon_weights = {}
                for i, feature_name in enumerate(horizon_features):
                    # Ø­Ø°Ù prefix Ø§ÙÙ‚
                    clean_name = feature_name.replace(f'{horizon}_', '')
                    horizon_weights[clean_name] = float(w[i])
                
                weights[horizon] = horizon_weights
                
                # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
                predictions = X @ w
                mae = np.mean(np.abs(predictions - y))
                rmse = np.sqrt(np.mean((predictions - y) ** 2))
                
                # Ø¯Ù‚Øª Ø¬Ù‡Øª
                direction_correct = np.sum((predictions > 0) == (y > 0)) / len(y)
                
                print(f"    MAE: {mae:.4f}")
                print(f"    RMSE: {rmse:.4f}")
                print(f"    Direction Accuracy: {direction_correct:.2%}")
                
            except Exception as e:
                print(f"    âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ {horizon}: {e}")
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
                weights[horizon] = self._get_default_weights(horizon)
        
        # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w') as f:
            json.dump(weights, f, indent=2)
        
        print(f"\nâœ… ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {output_path}")
        
        return weights
    
    def _get_default_weights(self, horizon: str) -> Dict[str, float]:
        """ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶"""
        return {
            'nearest_resistance_dist': -0.3,
            'resistance_strength': -0.2,
            'nearest_support_dist': 0.3,
            'support_strength': 0.2,
            'sr_position': -0.35,
            'sr_bias': 0.25,
            'level_density': 0.15,
            'fib_signal': 0.2,
            'camarilla_signal': 0.15
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ø¬Ø±Ø§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("=" * 70)
    print("Multi-Horizon Support/Resistance Training Pipeline")
    print("=" * 70)
    
    # Ø§ÛŒØ¬Ø§Ø¯ trainer
    trainer = MultiHorizonSupportResistanceTrainer()
    
    # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ Ø¢Ù…ÙˆØ²Ø´
    features_df, targets_df = trainer.prepare_training_data(num_samples=2000)
    
    # Ø¢Ù…ÙˆØ²Ø´
    weights = trainer.train(features_df, targets_df)
    
    # ØªØ³Øª Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ validation
    print("\n" + "=" * 70)
    print("ğŸ§ª ØªØ³Øª Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ Validation")
    print("=" * 70)
    
    features_val, targets_val = trainer.prepare_training_data(num_samples=600)
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ analyzer Ø¨Ø§ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
    analyzer = MultiHorizonSupportResistanceAnalyzer(
        weights_path="models/support_resistance/sr_weights.json"
    )
    
    # ØªØ³Øª Ø±ÙˆÛŒ Ú†Ù†Ø¯ Ù†Ù…ÙˆÙ†Ù‡
    print("\nØªØ³Øª Ø±ÙˆÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ validation:")
    
    for scenario in ['bounce', 'breakout', 'consolidation', 'fake_out']:
        scenario_indices = targets_val[targets_val['scenario'] == scenario].index[:3]
        
        print(f"\nğŸ“Š Ø³Ù†Ø§Ø±ÛŒÙˆ: {scenario.upper()}")
        
        for idx in scenario_indices:
            # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¬Ø¯Ø¯ candles (Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒ Ø§Ø² ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…)
            if scenario == 'bounce':
                candles, _ = create_bounce_scenario()
            elif scenario == 'breakout':
                candles, _ = create_breakout_scenario()
            elif scenario == 'consolidation':
                candles, _ = create_consolidation_scenario()
            else:
                candles, _ = create_fake_out_scenario()
            
            try:
                analysis = analyzer.analyze(candles)
                print(f"\n  Target: {targets_val.loc[idx, '3d_target']:+.2f}")
                print(f"  Predicted 3d: {analysis.score_3d.score:+.2f}")
                print(f"  Signal: {analysis.score_3d.signal}")
                print(f"  Bounce Prob: {analysis.score_3d.bounce_probability:.1%}")
                print(f"  Breakout Prob: {analysis.score_3d.breakout_probability:.1%}")
            except Exception as e:
                print(f"  âš ï¸  Ø®Ø·Ø§: {e}")
            
            break  # ÙÙ‚Ø· ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ù‡Ø± Ø³Ù†Ø§Ø±ÛŒÙˆ
    
    print("\n" + "=" * 70)
    print("âœ… Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print("=" * 70)
